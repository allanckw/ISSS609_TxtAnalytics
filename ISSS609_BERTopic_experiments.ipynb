{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Ba6lgKaOHlQJlu2ZNm_oiNKDM8L4y2sK","timestamp":1678633829936}],"authorship_tag":"ABX9TyO7X4+EOs4+yK3H1ADE9GRD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vXvDVb8mFiU4"},"outputs":[],"source":["!pip install --upgrade llvmlite\n","!pip install --upgrade git+https://github.com/scikit-learn-contrib/hdbscan.git#egg=hdbscan\n","!pip install bertopic\n","# !pip install bertopic[flair]\n","# !pip install bertopic[gensim]\n","# !pip install bertopic[spacy]\n","# !pip install bertopic[use]\n","!pip install git+https://github.com/MartinoMensio/spacy-universal-sentence-encoder.git"]},{"cell_type":"code","source":["import pandas as pd\n","\n","from bertopic import BERTopic\n","import pandas as pd\n","import numpy as np\n","import multiprocessing\n","import time\n","import csv\n","import io\n","\n","multiprocessing.cpu_count()\n","\n","\n","from google.colab import drive\n","#import os\n","!pip install pandas==1.5.3\n","#!pip install pandas==1.3.5\n","import pandas as pd\n","\n","drive.mount('/content/gdrive', force_remount=True)\n","%cd gdrive/MyDrive/MITB_AI/Text analytics dataset"],"metadata":{"id":"Fi4A8VBxFuz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%ls"],"metadata":{"id":"maiO1jXDFy4k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = pd.read_pickle(\"X_Train.pkl\")\n","\n","from nltk.classify.scikitlearn import SklearnClassifier\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.experimental import enable_halving_search_cv\n","from sklearn.model_selection import HalvingGridSearchCV\n","\n","vectorizer = CountVectorizer(analyzer='word',       \n","                             min_df=10,                        # min occurrences of a word \n","                             stop_words='english',             # remove stop words\n","                             lowercase=False,                   # convert all words to lowercase\n","                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n","                             # max_features=50000,             # max number of uniq words\n","                            )\n","\n","df_filtered_lemmatized = X_train[\"text_lemmatized\"].tolist()\n","\n","stop_list = (\"suicidal\", \"suicide\", \"aah\", \"fuck\")\n","df_filtered_lemmatized_removeSuicide = [[w for w in doc if w not in stop_list] for doc in df_filtered_lemmatized]\n","df_filtered_lemmatized_joined = [' '.join(x) for x in df_filtered_lemmatized_removeSuicide]  # joined to fit CountVectorizer\n","train1_vecs = vectorizer.fit_transform(df_filtered_lemmatized_joined) #may be needed for bertopic\n","feature_names = vectorizer.get_feature_names_out()\n","# display the first 20 tokens\n","feature_names[:20]"],"metadata":{"id":"GVFHUGhFF0ZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train1_vecs.shape)"],"metadata":{"id":"xyRkiib9F2uf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_time = time.time()\n","\n","model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n","topics, probs = topic_model.fit_transform(df_filtered_lemmatized_joined)\n","\n","print('Total time taken (mins): ', int((time.time()-start_time)/60))"],"metadata":{"id":"lcZIm1HIF5L9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.get_topic_info().head()"],"metadata":{"id":"-E0QOdtNGJgJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n","joblib.dump(model, 'BERTopic_X_Train.jl')"],"metadata":{"id":"osAbtt4pGY1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n","model = joblib.load('BERTopic_X_Train.jl')"],"metadata":{"id":"atwtAO1eGzA9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.reduce_topics(df_filtered_lemmatized_joined, nr_topics=30)"],"metadata":{"id":"idsGs9_dG5Kk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topic_keywords = model.get_topics()\n","\n","df_topic_keywords = pd.DataFrame(topic_keywords)\n","df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n","df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n","df_topic_keywords"],"metadata":{"id":"_BPGkNDGHcnp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_topic_keywords.to_csv('BERTopic_X_Train_TopicsOutput.csv')"],"metadata":{"id":"W1LLd1jFHi6b"},"execution_count":null,"outputs":[]}]}