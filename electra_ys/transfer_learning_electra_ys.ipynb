{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "392eb13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # !pip install wandb\n",
    "# # # !pip install transformers\n",
    "# # !pip install datasets\n",
    "# !pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10928698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/projectgrps/IS424/IS424G10/jupyterlab-venv-pytorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-03-01 13:52:12.214248: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-01 13:52:13.068128: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/CUDA/11.7.0/nvvm/lib64:/opt/apps/software/CUDA/11.7.0/extras/CUPTI/lib64:/opt/apps/software/CUDA/11.7.0/lib:/opt/apps/software/Python/3.7.13-GCCcore-11.2.0/lib:/opt/apps/software/OpenSSL/1.1/lib:/opt/apps/software/libffi/3.4.2-GCCcore-11.2.0/lib64:/opt/apps/software/GMP/6.2.1-GCCcore-11.2.0/lib:/opt/apps/software/XZ/5.2.5-GCCcore-11.2.0/lib:/opt/apps/software/SQLite/3.36-GCCcore-11.2.0/lib:/opt/apps/software/Tcl/8.6.11-GCCcore-11.2.0/lib:/opt/apps/software/libreadline/8.1-GCCcore-11.2.0/lib:/opt/apps/software/ncurses/6.2-GCCcore-11.2.0/lib:/opt/apps/software/bzip2/1.0.8-GCCcore-11.2.0/lib:/opt/apps/software/binutils/2.37-GCCcore-11.2.0/lib:/opt/apps/software/zlib/1.2.11-GCCcore-11.2.0/lib:/opt/apps/software/GCCcore/11.2.0/lib64\n",
      "2023-03-01 13:52:13.069201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/CUDA/11.7.0/nvvm/lib64:/opt/apps/software/CUDA/11.7.0/extras/CUPTI/lib64:/opt/apps/software/CUDA/11.7.0/lib:/opt/apps/software/Python/3.7.13-GCCcore-11.2.0/lib:/opt/apps/software/OpenSSL/1.1/lib:/opt/apps/software/libffi/3.4.2-GCCcore-11.2.0/lib64:/opt/apps/software/GMP/6.2.1-GCCcore-11.2.0/lib:/opt/apps/software/XZ/5.2.5-GCCcore-11.2.0/lib:/opt/apps/software/SQLite/3.36-GCCcore-11.2.0/lib:/opt/apps/software/Tcl/8.6.11-GCCcore-11.2.0/lib:/opt/apps/software/libreadline/8.1-GCCcore-11.2.0/lib:/opt/apps/software/ncurses/6.2-GCCcore-11.2.0/lib:/opt/apps/software/bzip2/1.0.8-GCCcore-11.2.0/lib:/opt/apps/software/binutils/2.37-GCCcore-11.2.0/lib:/opt/apps/software/zlib/1.2.11-GCCcore-11.2.0/lib:/opt/apps/software/GCCcore/11.2.0/lib64\n",
      "2023-03-01 13:52:13.069211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import ElectraForSequenceClassification, ElectraTokenizer, Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "from transformers import ElectraForSequenceClassification, ElectraTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23b8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcb0744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60310bb6",
   "metadata": {},
   "source": [
    "Set some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c4122f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def set_random_seed(seed):\n",
    "    SEED = seed\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75164f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "set_random_seed(0)\n",
    "MODEL_SAVE_PATH = \"electra_ys\"\n",
    "MODEL_CHECKPOINT_PATH = \"electra_checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51602afa",
   "metadata": {},
   "source": [
    "# Load and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ce1cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>char_length</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex wife threatening suicide recently left wif...</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weird affected compliment coming know girl fee...</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finally thousand hear thousand bad year swear ...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need help help hard</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ism lost hello adam sixteen 've struggling yea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1376</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class  char_length  \\\n",
       "0  sex wife threatening suicide recently left wif...      1          364   \n",
       "1  weird affected compliment coming know girl fee...      0           76   \n",
       "2  finally thousand hear thousand bad year swear ...      0           66   \n",
       "3                                need help help hard      1           33   \n",
       "4  ism lost hello adam sixteen 've struggling yea...      1         1376   \n",
       "\n",
       "   token_length  \n",
       "0            54  \n",
       "1            11  \n",
       "2            10  \n",
       "3             6  \n",
       "4           193  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a8a3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['char_length']\n",
    "del df['token_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4fb6f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex wife threatening suicide recently left wif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weird affected compliment coming know girl fee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finally thousand hear thousand bad year swear ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need help help hard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ism lost hello adam sixteen 've struggling yea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  sex wife threatening suicide recently left wif...      1\n",
       "1  weird affected compliment coming know girl fee...      0\n",
       "2  finally thousand hear thousand bad year swear ...      0\n",
       "3                                need help help hard      1\n",
       "4  ism lost hello adam sixteen 've struggling yea...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee68d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation and test sets\n",
    "train, test = train_test_split(df,\n",
    "                               random_state=0,\n",
    "                               test_size=0.2,\n",
    "                               stratify=df['class'])\n",
    "\n",
    "train, val = train_test_split(train,\n",
    "                             random_state=0,\n",
    "                             test_size=0.125,\n",
    "                             stratify=train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dcd4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[\"text\"].values.tolist()\n",
    "train_labels = train[\"class\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21cc7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val[\"text\"].values.tolist()\n",
    "val_labels = val[\"class\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b391d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test[\"text\"].values.tolist()\n",
    "test_labels = test[\"class\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4335799c",
   "metadata": {},
   "source": [
    "# Load the pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699fde6d",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/model_doc/electra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602db676",
   "metadata": {},
   "source": [
    "https://huggingface.co/course/chapter3/3?fw=pt#training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e46f4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-base-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e45cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_data, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_data, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_data, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00faceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cea5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_encodings, train_labels)\n",
    "val_dataset = Dataset(val_encodings, val_labels)\n",
    "test_dataset = Dataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81073a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric_accuracy  = evaluate.load(\"accuracy\")\n",
    "metric_precision = evaluate.load(\"precision\")\n",
    "metric_recall = evaluate.load(\"recall\")\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = metric_accuracy.compute(predictions=predictions, references=labels)\n",
    "    precision = metric_precision.compute(predictions=predictions, references=labels)\n",
    "    recall = metric_recall.compute(predictions=predictions, references=labels)\n",
    "    f1 = metric_f1.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    return {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "839836ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Set training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "# Load the pretrained model.\n",
    "# The \".to('cuda')\" method moves the model into GPU. \n",
    "# If your machine does't have a GPU, please comment out \".to('cuda')\" from this line.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\", num_labels=2).to('cuda')\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6445954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/projectgrps/IS424/IS424G10/jupyterlab-venv-pytorch/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 162392\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15225\n",
      "  Number of trainable parameters = 109483778\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mystan98\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/common/home/projectgrps/IS424/IS424G10/wandb/run-20230301_135308-yyojak6b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ystan98/huggingface/runs/yyojak6b' target=\"_blank\">blooming-tree-15</a></strong> to <a href='https://wandb.ai/ystan98/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ystan98/huggingface' target=\"_blank\">https://wandb.ai/ystan98/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ystan98/huggingface/runs/yyojak6b' target=\"_blank\">https://wandb.ai/ystan98/huggingface/runs/yyojak6b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15225' max='15225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15225/15225 4:29:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.223053</td>\n",
       "      <td>{'accuracy': 0.9183585499374973}</td>\n",
       "      <td>{'precision': 0.9254097642212289}</td>\n",
       "      <td>{'recall': 0.910093957417464}</td>\n",
       "      <td>{'f1': 0.9176879617557584}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>0.218066</td>\n",
       "      <td>{'accuracy': 0.9255140307771886}</td>\n",
       "      <td>{'precision': 0.9382935274793572}</td>\n",
       "      <td>{'recall': 0.9109559520730971}</td>\n",
       "      <td>{'f1': 0.9244226731980405}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.208100</td>\n",
       "      <td>0.204233</td>\n",
       "      <td>{'accuracy': 0.9304711409974568}</td>\n",
       "      <td>{'precision': 0.924804355222865}</td>\n",
       "      <td>{'recall': 0.9371605896043445}</td>\n",
       "      <td>{'f1': 0.9309414736481569}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.186534</td>\n",
       "      <td>{'accuracy': 0.9325401956980904}</td>\n",
       "      <td>{'precision': 0.9407166695942385}</td>\n",
       "      <td>{'recall': 0.923282475648651}</td>\n",
       "      <td>{'f1': 0.9319180406316613}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.177520</td>\n",
       "      <td>{'accuracy': 0.9359886201991465}</td>\n",
       "      <td>{'precision': 0.9220627503337784}</td>\n",
       "      <td>{'recall': 0.9525040944746143}</td>\n",
       "      <td>{'f1': 0.9370362518549926}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.180793</td>\n",
       "      <td>{'accuracy': 0.9364627785680417}</td>\n",
       "      <td>{'precision': 0.9264}</td>\n",
       "      <td>{'recall': 0.9482803206620118}</td>\n",
       "      <td>{'f1': 0.9372124723121487}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.184944</td>\n",
       "      <td>{'accuracy': 0.9394370447002026}</td>\n",
       "      <td>{'precision': 0.9306470687616152}</td>\n",
       "      <td>{'recall': 0.949659512111025}</td>\n",
       "      <td>{'f1': 0.9400571696744742}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.178206</td>\n",
       "      <td>{'accuracy': 0.9396094659252554}</td>\n",
       "      <td>{'precision': 0.9382949467170849}</td>\n",
       "      <td>{'recall': 0.9411257650202569}</td>\n",
       "      <td>{'f1': 0.9397082239531781}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.165307</td>\n",
       "      <td>{'accuracy': 0.9406870985818354}</td>\n",
       "      <td>{'precision': 0.9404669595933488}</td>\n",
       "      <td>{'recall': 0.9409533660891303}</td>\n",
       "      <td>{'f1': 0.9407100999655291}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.167923</td>\n",
       "      <td>{'accuracy': 0.9409888357256778}</td>\n",
       "      <td>{'precision': 0.9442514762070163}</td>\n",
       "      <td>{'recall': 0.9373329885354711}</td>\n",
       "      <td>{'f1': 0.9407795129125752}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.168569</td>\n",
       "      <td>{'accuracy': 0.9419802577697315}</td>\n",
       "      <td>{'precision': 0.9405447203367987}</td>\n",
       "      <td>{'recall': 0.9436255495215929}</td>\n",
       "      <td>{'f1': 0.9420826161790017}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.163666</td>\n",
       "      <td>{'accuracy': 0.939738781844045}</td>\n",
       "      <td>{'precision': 0.9248771549929208}</td>\n",
       "      <td>{'recall': 0.9572450650805965}</td>\n",
       "      <td>{'f1': 0.9407827854964419}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.169322</td>\n",
       "      <td>{'accuracy': 0.9404715720505195}</td>\n",
       "      <td>{'precision': 0.9429611650485437}</td>\n",
       "      <td>{'recall': 0.9376777863977244}</td>\n",
       "      <td>{'f1': 0.9403120542853438}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.146100</td>\n",
       "      <td>0.174648</td>\n",
       "      <td>{'accuracy': 0.9384025173498858}</td>\n",
       "      <td>{'precision': 0.9577033837293016}</td>\n",
       "      <td>{'recall': 0.9173347125247824}</td>\n",
       "      <td>{'f1': 0.9370844890591291}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.171089</td>\n",
       "      <td>{'accuracy': 0.9427992585887323}</td>\n",
       "      <td>{'precision': 0.9470844212358572}</td>\n",
       "      <td>{'recall': 0.9380225842599776}</td>\n",
       "      <td>{'f1': 0.9425317223160539}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.163799</td>\n",
       "      <td>{'accuracy': 0.9398249924565714}</td>\n",
       "      <td>{'precision': 0.9229876481803863}</td>\n",
       "      <td>{'recall': 0.9597448495819326}</td>\n",
       "      <td>{'f1': 0.9410074374577417}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.159716</td>\n",
       "      <td>{'accuracy': 0.9434889434889435}</td>\n",
       "      <td>{'precision': 0.9473135106937924}</td>\n",
       "      <td>{'recall': 0.939229376777864}</td>\n",
       "      <td>{'f1': 0.9432541228411895}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.156670</td>\n",
       "      <td>{'accuracy': 0.9441355230828915}</td>\n",
       "      <td>{'precision': 0.943149565666122}</td>\n",
       "      <td>{'recall': 0.9452633393672959}</td>\n",
       "      <td>{'f1': 0.9442052695023249}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.135500</td>\n",
       "      <td>0.159947</td>\n",
       "      <td>{'accuracy': 0.9438768912453123}</td>\n",
       "      <td>{'precision': 0.9416002058142526}</td>\n",
       "      <td>{'recall': 0.9464701318851824}</td>\n",
       "      <td>{'f1': 0.9440288883157081}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.133200</td>\n",
       "      <td>0.163532</td>\n",
       "      <td>{'accuracy': 0.944221733695418}</td>\n",
       "      <td>{'precision': 0.9484814202419285}</td>\n",
       "      <td>{'recall': 0.939487975174554}</td>\n",
       "      <td>{'f1': 0.9439632773254808}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.168987</td>\n",
       "      <td>{'accuracy': 0.9440062071641019}</td>\n",
       "      <td>{'precision': 0.9398053278688525}</td>\n",
       "      <td>{'recall': 0.9487975174553918}</td>\n",
       "      <td>{'f1': 0.9442800154420281}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.178961</td>\n",
       "      <td>{'accuracy': 0.9434027328764171}</td>\n",
       "      <td>{'precision': 0.9390576988733356}</td>\n",
       "      <td>{'recall': 0.9483665201275752}</td>\n",
       "      <td>{'f1': 0.9436891538362567}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.179312</td>\n",
       "      <td>{'accuracy': 0.9434027328764171}</td>\n",
       "      <td>{'precision': 0.9439074905074215}</td>\n",
       "      <td>{'recall': 0.9428497543315232}</td>\n",
       "      <td>{'f1': 0.943378325930398}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.171592</td>\n",
       "      <td>{'accuracy': 0.9438768912453123}</td>\n",
       "      <td>{'precision': 0.9421310208637418}</td>\n",
       "      <td>{'recall': 0.9458667356262391}</td>\n",
       "      <td>{'f1': 0.9439951823812801}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.173625</td>\n",
       "      <td>{'accuracy': 0.944221733695418}</td>\n",
       "      <td>{'precision': 0.9445354955576641}</td>\n",
       "      <td>{'recall': 0.9438841479182829}</td>\n",
       "      <td>{'f1': 0.9442097094076054}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.174315</td>\n",
       "      <td>{'accuracy': 0.9448683132893659}</td>\n",
       "      <td>{'precision': 0.9456052495251251}</td>\n",
       "      <td>{'recall': 0.9440565468494095}</td>\n",
       "      <td>{'f1': 0.9448302635551913}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.178107</td>\n",
       "      <td>{'accuracy': 0.9440062071641019}</td>\n",
       "      <td>{'precision': 0.9487715629900679}</td>\n",
       "      <td>{'recall': 0.9387121799844841}</td>\n",
       "      <td>{'f1': 0.9437150656440919}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>0.169914</td>\n",
       "      <td>{'accuracy': 0.9450407345144187}</td>\n",
       "      <td>{'precision': 0.9431759656652361}</td>\n",
       "      <td>{'recall': 0.9471597276096888}</td>\n",
       "      <td>{'f1': 0.9451636488753172}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.172795</td>\n",
       "      <td>{'accuracy': 0.9449976292081556}</td>\n",
       "      <td>{'precision': 0.943551851533637}</td>\n",
       "      <td>{'recall': 0.9466425308163089}</td>\n",
       "      <td>{'f1': 0.9450946643717728}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.174223</td>\n",
       "      <td>{'accuracy': 0.9451700504332083}</td>\n",
       "      <td>{'precision': 0.944947014732489}</td>\n",
       "      <td>{'recall': 0.9454357382984225}</td>\n",
       "      <td>{'f1': 0.9451913133402274}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9183585499374973}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9254097642212289}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.910093957417464}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9176879617557584}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9255140307771886}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9382935274793572}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9109559520730971}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9244226731980405}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9304711409974568}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.924804355222865}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9371605896043445}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9309414736481569}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9325401956980904}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9407166695942385}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.923282475648651}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9319180406316613}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9359886201991465}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9220627503337784}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9525040944746143}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9370362518549926}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9364627785680417}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9264}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9482803206620118}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9372124723121487}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/config.json\n",
      "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9394370447002026}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9306470687616152}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.949659512111025}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9400571696744742}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "Configuration saved in ./results/checkpoint-3500/config.json\n",
      "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9396094659252554}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9382949467170849}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9411257650202569}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9397082239531781}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "Configuration saved in ./results/checkpoint-4000/config.json\n",
      "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9406870985818354}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9404669595933488}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9409533660891303}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9407100999655291}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "Configuration saved in ./results/checkpoint-4500/config.json\n",
      "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9409888357256778}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9442514762070163}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9373329885354711}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9407795129125752}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-5000\n",
      "Configuration saved in ./results/checkpoint-5000/config.json\n",
      "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9419802577697315}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9405447203367987}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9436255495215929}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9420826161790017}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-5500\n",
      "Configuration saved in ./results/checkpoint-5500/config.json\n",
      "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.939738781844045}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9248771549929208}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9572450650805965}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9407827854964419}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-6000\n",
      "Configuration saved in ./results/checkpoint-6000/config.json\n",
      "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9404715720505195}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9429611650485437}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9376777863977244}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9403120542853438}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-6500\n",
      "Configuration saved in ./results/checkpoint-6500/config.json\n",
      "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9384025173498858}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9577033837293016}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9173347125247824}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9370844890591291}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-7000\n",
      "Configuration saved in ./results/checkpoint-7000/config.json\n",
      "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9427992585887323}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9470844212358572}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9380225842599776}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9425317223160539}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-7500\n",
      "Configuration saved in ./results/checkpoint-7500/config.json\n",
      "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9398249924565714}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9229876481803863}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9597448495819326}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9410074374577417}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-8000\n",
      "Configuration saved in ./results/checkpoint-8000/config.json\n",
      "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9434889434889435}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9473135106937924}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.939229376777864}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9432541228411895}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-8500\n",
      "Configuration saved in ./results/checkpoint-8500/config.json\n",
      "Model weights saved in ./results/checkpoint-8500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9441355230828915}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943149565666122}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9452633393672959}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9442052695023249}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-9000\n",
      "Configuration saved in ./results/checkpoint-9000/config.json\n",
      "Model weights saved in ./results/checkpoint-9000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9438768912453123}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9416002058142526}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9464701318851824}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9440288883157081}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-9500\n",
      "Configuration saved in ./results/checkpoint-9500/config.json\n",
      "Model weights saved in ./results/checkpoint-9500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.944221733695418}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9484814202419285}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.939487975174554}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9439632773254808}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-10000\n",
      "Configuration saved in ./results/checkpoint-10000/config.json\n",
      "Model weights saved in ./results/checkpoint-10000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9440062071641019}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9398053278688525}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9487975174553918}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9442800154420281}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-10500\n",
      "Configuration saved in ./results/checkpoint-10500/config.json\n",
      "Model weights saved in ./results/checkpoint-10500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9434027328764171}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9390576988733356}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9483665201275752}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9436891538362567}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-11000\n",
      "Configuration saved in ./results/checkpoint-11000/config.json\n",
      "Model weights saved in ./results/checkpoint-11000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9434027328764171}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9439074905074215}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9428497543315232}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.943378325930398}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-11500\n",
      "Configuration saved in ./results/checkpoint-11500/config.json\n",
      "Model weights saved in ./results/checkpoint-11500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9438768912453123}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9421310208637418}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9458667356262391}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9439951823812801}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-12000\n",
      "Configuration saved in ./results/checkpoint-12000/config.json\n",
      "Model weights saved in ./results/checkpoint-12000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.944221733695418}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9445354955576641}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9438841479182829}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9442097094076054}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-12500\n",
      "Configuration saved in ./results/checkpoint-12500/config.json\n",
      "Model weights saved in ./results/checkpoint-12500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9448683132893659}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9456052495251251}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9440565468494095}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9448302635551913}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-13000\n",
      "Configuration saved in ./results/checkpoint-13000/config.json\n",
      "Model weights saved in ./results/checkpoint-13000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9440062071641019}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9487715629900679}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9387121799844841}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9437150656440919}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-13500\n",
      "Configuration saved in ./results/checkpoint-13500/config.json\n",
      "Model weights saved in ./results/checkpoint-13500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9450407345144187}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9431759656652361}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9471597276096888}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9451636488753172}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-14000\n",
      "Configuration saved in ./results/checkpoint-14000/config.json\n",
      "Model weights saved in ./results/checkpoint-14000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9449976292081556}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.943551851533637}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9466425308163089}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9450946643717728}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-14500\n",
      "Configuration saved in ./results/checkpoint-14500/config.json\n",
      "Model weights saved in ./results/checkpoint-14500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9451700504332083}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.944947014732489}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9454357382984225}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9451913133402274}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results/checkpoint-15000\n",
      "Configuration saved in ./results/checkpoint-15000/config.json\n",
      "Model weights saved in ./results/checkpoint-15000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15225, training_loss=0.14811112502525592, metrics={'train_runtime': 16151.0181, 'train_samples_per_second': 30.164, 'train_steps_per_second': 0.943, 'total_flos': 1.2818139150606336e+17, 'train_loss': 0.14811112502525592, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the text classification model.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "391d69e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to electra_ys\n",
      "Configuration saved in electra_ys/config.json\n",
      "Model weights saved in electra_ys/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('electra_ys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2e3ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 23199\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.9452131557394715}\" of type <class 'dict'> for key \"eval/Accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9444922547332186}\" of type <class 'dict'> for key \"eval/Precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.9460391345573658}\" of type <class 'dict'> for key \"eval/Recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9452650617975109}\" of type <class 'dict'> for key \"eval/F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.17375293374061584,\n",
       " 'eval_Accuracy': {'accuracy': 0.9452131557394715},\n",
       " 'eval_Precision': {'precision': 0.9444922547332186},\n",
       " 'eval_Recall': {'recall': 0.9460391345573658},\n",
       " 'eval_F1': {'f1': 0.9452650617975109},\n",
       " 'eval_runtime': 179.1751,\n",
       " 'eval_samples_per_second': 129.477,\n",
       " 'eval_steps_per_second': 4.046,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42bf9184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 46398\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.15672726929187775,\n",
       " 'test_Accuracy': {'accuracy': 0.948855554118712},\n",
       " 'test_Precision': {'precision': 0.9505147504109352},\n",
       " 'test_Recall': {'recall': 0.9470327112873336},\n",
       " 'test_F1': {'f1': 0.9487705360419681},\n",
       " 'test_runtime': 351.0832,\n",
       " 'test_samples_per_second': 132.157,\n",
       " 'test_steps_per_second': 4.13}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(test_dataset).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a383ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ad141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679d34c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "449eb573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file electra_ys/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"electra_ys\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file electra_ys/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at electra_ys.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "saved_model = AutoModelForSequenceClassification.from_pretrained('electra_ys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d53e5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 0 = positive, label 1 = suicidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "19547d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"i wish i could die right now\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "37f32b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_encodings = tokenizer(test_text, truncation=True, padding=True,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6b293a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.to('cuda')\n",
    "# Pass your inputs to the model and return the logits:\n",
    "with torch.no_grad():\n",
    "    logits = saved_model(**unseen_encodings.to('cuda')).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f1895bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LABEL_1'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = torch.sigmoid(logits)\n",
    "predicted_class_id = probabilities.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "18839692",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"i wish i could die right now. just kidding haha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f36e905e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LABEL_0'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_encodings = tokenizer(test_text, truncation=True, padding=True,return_tensors=\"pt\")\n",
    "saved_model.to('cuda')\n",
    "# Pass your inputs to the model and return the logits:\n",
    "with torch.no_grad():\n",
    "    logits = saved_model(**unseen_encodings.to('cuda')).logits\n",
    "probabilities = torch.sigmoid(logits)\n",
    "predicted_class_id = probabilities.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "c12be79be354b77035343c00a9548d38cff49c79dc06b63ac2e90540ac33eaf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
