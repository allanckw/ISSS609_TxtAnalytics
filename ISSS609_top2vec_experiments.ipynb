{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HymzvC2i2Jhw"
   },
   "source": [
    "https://colab.research.google.com/drive/1T88YY-c2t37z73E_Qo_u1NBvyjy3kEim?usp=sharing#scrollTo=HU0KTERNllyB\n",
    "\n",
    "https://towardsdatascience.com/how-to-perform-topic-modeling-with-top2vec-1ae9bb4e89dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128326,
     "status": "ok",
     "timestamp": 1678626731346,
     "user": {
      "displayName": "Damien Mak",
      "userId": "03773984173715336414"
     },
     "user_tz": -480
    },
    "id": "QTsy_XKdjzqh",
    "outputId": "b5cb2a78-2d34-4ef0-b296-3685452c86ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: llvmlite in /usr/local/lib/python3.9/dist-packages (0.39.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting hdbscan\n",
      "  Cloning https://github.com/scikit-learn-contrib/hdbscan.git to /tmp/pip-install-dgnirk7w/hdbscan_1b0be07f5058447c9cbc5d8401c7d27c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/scikit-learn-contrib/hdbscan.git /tmp/pip-install-dgnirk7w/hdbscan_1b0be07f5058447c9cbc5d8401c7d27c\n",
      "  Resolved https://github.com/scikit-learn-contrib/hdbscan.git to commit e55f957441fa58c109971fb868a399b498578234\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (1.2.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (1.10.1)\n",
      "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (0.29.33)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20->hdbscan) (3.1.0)\n",
      "Building wheels for collected packages: hdbscan\n",
      "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp39-cp39-linux_x86_64.whl size=3582036 sha256=05bd3518394bf4addd40f7f120cf7e4f8aaa3cb6d91affa6cea5e81419f3e640\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_a2a86qx/wheels/d9/a3/52/1cab90885b0cdba2193151c1edfb01b1bc3c2c6abdb94eebda\n",
      "Successfully built hdbscan\n",
      "Installing collected packages: hdbscan\n",
      "Successfully installed hdbscan-0.8.29\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting top2vec\n",
      "  Downloading top2vec-1.0.28-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from top2vec) (1.2.1)\n",
      "Collecting umap-learn>=0.5.1\n",
      "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting gensim>=4.0.0\n",
      "  Downloading gensim-4.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.9/dist-packages (from top2vec) (1.22.4)\n",
      "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.9/dist-packages (from top2vec) (0.8.29)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from top2vec) (1.3.5)\n",
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.9/dist-packages (from top2vec) (1.8.2.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim>=4.0.0->top2vec) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim>=4.0.0->top2vec) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.9/dist-packages (from hdbscan>=0.8.27->top2vec) (1.2.0)\n",
      "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.9/dist-packages (from hdbscan>=0.8.27->top2vec) (0.29.33)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.2.0->top2vec) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.5.1->top2vec) (0.56.4)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.5.1->top2vec) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas->top2vec) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->top2vec) (2022.7.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from wordcloud->top2vec) (3.5.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from wordcloud->top2vec) (8.4.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (57.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas->top2vec) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec) (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec) (4.39.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec) (0.11.0)\n",
      "Building wheels for collected packages: umap-learn, pynndescent\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=7015aa28ae1135e28a52b4c6821996279d1cc2b29adc0f2f15db18fea659d4c2\n",
      "  Stored in directory: /root/.cache/pip/wheels/f4/3e/1c/596d0a463d17475af648688443fa4846fef624d1390339e7e9\n",
      "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55513 sha256=0c7616e12f175e08172f6496a6b314f740b21e59423f246dd373ed3cfbec5414\n",
      "  Stored in directory: /root/.cache/pip/wheels/b9/89/cc/59ab91ef5b21dc2ab3635528d7d227f49dfc9169905dcb959d\n",
      "Successfully built umap-learn pynndescent\n",
      "Installing collected packages: gensim, pynndescent, umap-learn, top2vec\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 3.6.0\n",
      "    Uninstalling gensim-3.6.0:\n",
      "      Successfully uninstalled gensim-3.6.0\n",
      "Successfully installed gensim-4.3.1 pynndescent-0.5.8 top2vec-1.0.28 umap-learn-0.5.3\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: top2vec[sentence_encoders] in /usr/local/lib/python3.9/dist-packages (1.0.28)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_encoders]) (1.3.5)\n",
      "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_encoders]) (4.3.1)\n",
      "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_encoders]) (0.8.29)\n",
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_encoders]) (1.8.2.2)\n",
      "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_encoders]) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_encoders]) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_encoders]) (1.2.1)\n",
      "Collecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_encoders]) (0.12.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_encoders]) (2.11.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim>=4.0.0->top2vec[sentence_encoders]) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim>=4.0.0->top2vec[sentence_encoders]) (6.3.0)\n",
      "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.9/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (0.29.33)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.9/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.2.0->top2vec[sentence_encoders]) (3.1.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.5.8)\n",
      "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.56.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (4.65.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->top2vec[sentence_encoders]) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas->top2vec[sentence_encoders]) (2.8.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.15.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.19.6)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (23.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (15.0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (4.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (57.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.11.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (23.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.31.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.11.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.51.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from wordcloud->top2vec[sentence_encoders]) (3.5.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from wordcloud->top2vec[sentence_encoders]) (8.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->top2vec[sentence_encoders]) (0.38.4)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.39.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (2.16.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (2.2.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (1.8.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec[sentence_encoders]) (4.39.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec[sentence_encoders]) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec[sentence_encoders]) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec[sentence_encoders]) (0.11.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (6.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (1.26.14)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->top2vec[sentence_encoders]) (3.2.2)\n",
      "Installing collected packages: tensorflow-text\n",
      "Successfully installed tensorflow-text-2.11.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: top2vec[sentence_transformers] in /usr/local/lib/python3.9/dist-packages (1.0.28)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_transformers]) (1.3.5)\n",
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_transformers]) (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_transformers]) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_transformers]) (1.2.1)\n",
      "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_transformers]) (4.3.1)\n",
      "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_transformers]) (0.8.29)\n",
      "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_transformers]) (0.5.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from top2vec[sentence_transformers]) (1.13.1+cu116)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim>=4.0.0->top2vec[sentence_transformers]) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim>=4.0.0->top2vec[sentence_transformers]) (1.10.1)\n",
      "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.9/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_transformers]) (0.29.33)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.9/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_transformers]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.2.0->top2vec[sentence_transformers]) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_transformers]) (0.56.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_transformers]) (4.65.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_transformers]) (0.5.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas->top2vec[sentence_transformers]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->top2vec[sentence_transformers]) (2022.7.1)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers->top2vec[sentence_transformers]) (0.14.1+cu116)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers->top2vec[sentence_transformers]) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->top2vec[sentence_transformers]) (4.5.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from wordcloud->top2vec[sentence_transformers]) (3.5.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from wordcloud->top2vec[sentence_transformers]) (8.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers->top2vec[sentence_transformers]) (23.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers->top2vec[sentence_transformers]) (2.25.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers->top2vec[sentence_transformers]) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers->top2vec[sentence_transformers]) (6.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_transformers]) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_transformers]) (57.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas->top2vec[sentence_transformers]) (1.15.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->top2vec[sentence_transformers]) (2022.6.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec[sentence_transformers]) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec[sentence_transformers]) (4.39.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec[sentence_transformers]) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud->top2vec[sentence_transformers]) (1.4.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers->top2vec[sentence_transformers]) (8.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->top2vec[sentence_transformers]) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->top2vec[sentence_transformers]) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->top2vec[sentence_transformers]) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers->top2vec[sentence_transformers]) (1.26.14)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=897649d34999cef4696b02ab50e2249a377538ea159add0f30cc73a6d29d9005\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.13.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/MartinoMensio/spacy-universal-sentence-encoder.git\n",
      "  Cloning https://github.com/MartinoMensio/spacy-universal-sentence-encoder.git to /tmp/pip-req-build-1gz7qqw4\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/MartinoMensio/spacy-universal-sentence-encoder.git /tmp/pip-req-build-1gz7qqw4\n",
      "  Resolved https://github.com/MartinoMensio/spacy-universal-sentence-encoder.git to commit 8c95321ef126709fa823a49f93555fa93415a915\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tensorflow<3.0.0,>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from spacy-universal-sentence-encoder==0.4.5) (2.11.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy-universal-sentence-encoder==0.4.5) (3.4.4)\n",
      "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.9/dist-packages (from spacy-universal-sentence-encoder==0.4.5) (0.12.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (1.22.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (57.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (3.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (4.65.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (2.4.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (23.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (8.1.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (1.10.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (1.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (6.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (0.31.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (2.11.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (4.5.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (15.0.6.1)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (2.11.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (3.19.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (2.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (1.51.3)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (23.3.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (0.38.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (2.10)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (2.2.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.5) (2.1.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.5) (3.2.2)\n",
      "Building wheels for collected packages: spacy-universal-sentence-encoder\n",
      "  Building wheel for spacy-universal-sentence-encoder (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for spacy-universal-sentence-encoder: filename=spacy_universal_sentence_encoder-0.4.5-py3-none-any.whl size=15810 sha256=856fcea40482e36176f20fad5879a4a7fba8c16faf52d050e610dc4f3fff7de8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-bo6uwr27/wheels/f2/fe/8e/cb0116e0394cffa5cb341c49cc093cab128e5925039d9aa437\n",
      "Successfully built spacy-universal-sentence-encoder\n",
      "Installing collected packages: spacy-universal-sentence-encoder\n",
      "Successfully installed spacy-universal-sentence-encoder-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade llvmlite\n",
    "!pip install --upgrade git+https://github.com/scikit-learn-contrib/hdbscan.git#egg=hdbscan\n",
    "!pip install top2vec  # easy way to install Top2Vec\n",
    "!pip install top2vec[sentence_encoders]  # install if using pre-trained universal sentence encoder options\n",
    "!pip install top2vec[sentence_transformers]  # install if using pre-trained BERT sentence transformer options\n",
    "!pip install git+https://github.com/MartinoMensio/spacy-universal-sentence-encoder.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82806,
     "status": "ok",
     "timestamp": 1678626819046,
     "user": {
      "displayName": "Damien Mak",
      "userId": "03773984173715336414"
     },
     "user_tz": -480
    },
    "id": "qzH_0mBckAeU",
    "outputId": "ed02916a-1e18-42d0-a307-82bfe61db84e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pandas==1.5.3\n",
      "  Downloading pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas==1.5.3) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas==1.5.3) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "      Successfully uninstalled pandas-1.3.5\n",
      "Successfully installed pandas-1.5.3\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas==1.5.3) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas==1.5.3) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.15.0)\n",
      "Mounted at /content/gdrive\n",
      "/content/gdrive/MyDrive/MITB_AI/Text analytics dataset\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.5.3\n",
    "import pandas as pd\n",
    "\n",
    "from top2vec import Top2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "\n",
    "multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "#import os\n",
    "!pip install pandas==1.5.3\n",
    "#!pip install pandas==1.3.5\n",
    "import pandas as pd\n",
    "\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "%cd gdrive/MyDrive/MITB_AI/Text analytics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1678626500581,
     "user": {
      "displayName": "Damien Mak",
      "userId": "03773984173715336414"
     },
     "user_tz": -480
    },
    "id": "6tJvfBCXoGjq"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678626830312,
     "user": {
      "displayName": "Damien Mak",
      "userId": "03773984173715336414"
     },
     "user_tz": -480
    },
    "id": "tD_IrSFCDrdU",
    "outputId": "e8190c56-16d4-4d61-bea5-2237c6262975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts_after_lemmatized_non_suicidal.pkl\n",
      "posts_suicidal_with_tfidf2.pkl\n",
      "Top2VecModel_USE_X_Train.jl\n",
      "Top2VecModel_USE_X_Train_nonSuicidal.jl\n",
      "Top2VecModel_X_Train.jl\n",
      "Top2VecModel_X_Train_nonSuicidal.jl\n",
      "Top2Vec_USE_X_Train_nonSuicidal_TopicsOutput.csv\n",
      "Top2Vec_USE_X_Train_TopicsOutput.csv\n",
      "Top2Vec_X_Train_nonSuicidal_TopicsOutput.csv\n",
      "Top2Vec_X_Train_TopicsOutput.csv\n",
      "X_Train_nonSuicidal.pkl\n",
      "X_Train.pkl\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29419,
     "status": "ok",
     "timestamp": 1678626872217,
     "user": {
      "displayName": "Damien Mak",
      "userId": "03773984173715336414"
     },
     "user_tz": -480
    },
    "id": "QYkJpRNBoOHy",
    "outputId": "79ac3449-c654-49f1-e3cf-6ef550ea1e7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aaron', 'aba', 'aback', 'abandon', 'abandoned', 'abandonment',\n",
       "       'abdomen', 'abdominal', 'abhor', 'abhorrent', 'abide', 'ability',\n",
       "       'abject', 'able', 'abnormal', 'abnormality', 'abnormally',\n",
       "       'abomination', 'abort', 'aborted'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df2 = pd.read_csv(io.BytesIO(uploaded['Suicide_Detection_non-suicide only_processed.csv']))\n",
    "#df2 = pd.read_csv('Suicide_Detection_suicide only_processed_small.csv', engine='python', error_bad_lines=False, encoding='ISO-8859-1')\n",
    "#print(len(df2))\n",
    "#print(df2.head())\n",
    "\n",
    "#print(y_train.head())\n",
    "\n",
    "X_train = pd.read_pickle(\"X_Train.pkl\")\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,                        # min occurrences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=False,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )\n",
    "\n",
    "df_filtered_lemmatized = X_train[\"text_lemmatized\"].tolist()\n",
    "\n",
    "stop_list = (\"suicidal\", \"suicide\", \"aah\", \"fuck\")\n",
    "df_filtered_lemmatized_removeSuicide = [[w for w in doc if w not in stop_list] for doc in df_filtered_lemmatized]\n",
    "df_filtered_lemmatized_joined = [' '.join(x) for x in df_filtered_lemmatized_removeSuicide]  # joined to fit CountVectorizer\n",
    "train1_vecs = vectorizer.fit_transform(df_filtered_lemmatized_joined) #may be needed for bertopic\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "# display the first 20 tokens\n",
    "feature_names[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1678626872218,
     "user": {
      "displayName": "Damien Mak",
      "userId": "03773984173715336414"
     },
     "user_tz": -480
    },
    "id": "5GNqTrDvo-yS",
    "outputId": "b4babb38-7dc7-4077-8687-a0f2aad2dbf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81225, 11314)\n"
     ]
    }
   ],
   "source": [
    "#df2_list = [item for sublist in df2.values.tolist() for item in sublist]\n",
    "print(train1_vecs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXdZdAuMopDS",
    "outputId": "4b70af4a-3059-4f8a-f159-20d283813363"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 13:14:15,216 - top2vec - INFO - Pre-processing documents for training\n",
      "INFO:top2vec:Pre-processing documents for training\n",
      "2023-03-12 13:14:32,960 - top2vec - INFO - Creating joint document/word embedding\n",
      "INFO:top2vec:Creating joint document/word embedding\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#model = Top2Vec(documents=df_filtered_lemmatized_joined)\n",
    "#model = Top2Vec(documents=df_filtered_lemmatized_joined, embedding_model='universal-sentence-encoder')\n",
    "model = Top2Vec(documents=df_filtered_lemmatized_joined, speed=\"deep-learn\", workers=multiprocessing.cpu_count())  # uncomment to use Doc2Vec\n",
    "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svphsgSuQs2c"
   },
   "outputs": [],
   "source": [
    "#topic_words, word_scores, topic_nums = model.get_topics(num_topics=len(model.get_topic_sizes()))\n",
    "topic_words, word_scores, topic_nums = model.get_topics()\n",
    "\n",
    "\n",
    "print(topic_words)\n",
    "print(len(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cKTAQ3Tm089"
   },
   "outputs": [],
   "source": [
    "#topic_words, _, topic_docs = model.get_topics(num_topics=len(model.get_topic_sizes()))\n",
    "for i in range(len(topic_words)):\n",
    "    print(f\"Topic {i}: {' | '.join(topic_words[i])}\")\n",
    "    #print(f\"Documents: {', '.join(topic_docs[i])}\\n\")\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model, 'Top2VecModel_D2V_X_Train.jl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EB4XuaT1y6q"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "model = joblib.load('Top2VecModel_D2V_X_Train.jl')\n",
    "#nmf_output2 = joblib.load('suicidal_nmf_output2.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUdvXIDJJqla"
   },
   "outputs": [],
   "source": [
    "model.hierarchical_topic_reduction(num_topics=10)\n",
    "model.topic_words_reduced[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yfHmoKn18Ge"
   },
   "outputs": [],
   "source": [
    "topic_sizes, topic_nums = model.get_topic_sizes()\n",
    "print(topic_sizes[:10])  # get sizes of top 10 topics\n",
    "np.sum(topic_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gb1rE1z1-oa"
   },
   "outputs": [],
   "source": [
    "\n",
    "#topics, word_scores, topic_nums = model.get_topics(10)\n",
    "topics, word_scores, topic_nums = model.get_topics()\n",
    "\n",
    "# topic_words, word_scores, topic_nums = test.get_topics(test.get_num_topics())\n",
    "# for topic in topic_nums[:5]:\n",
    "#     test.generate_topic_wordcloud(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjaCm-5yYlNr"
   },
   "outputs": [],
   "source": [
    "topic_keywords = model.topic_words_reduced\n",
    "\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "td2yYKa68UJt"
   },
   "outputs": [],
   "source": [
    "df_topic_keywords.to_csv('Top2Vec_D2V_X_Train_TopicsOutput.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1o6ZRFQnAhW5WrMPgVfrkj1OXCpWthO4Z",
     "timestamp": 1678370647449
    },
    {
     "file_id": "1vHXAgljlwCBUpCmsG8e_a8jc55Fgszgy",
     "timestamp": 1678366122099
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
